{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b439fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from random import sample\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn import metrics\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "import cgcnn\n",
    "from cgcnn.data import CIFData\n",
    "from cgcnn.data import collate_pool, get_train_val_test_loader\n",
    "from cgcnn.model import CrystalGraphConvNet\n",
    "\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52a0565",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccde311",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\"\n",
    "model, preprocess = clip.load(\"RN50\", device=device)\n",
    "\n",
    "image = preprocess(Image.open(\"CLIP.png\")).unsqueeze(0).to(device)\n",
    "text = clip.tokenize([\"octopussy\",\"cat\",\"A new design strategy for high-performance organic cathode active materials for lithium-ion batteries is presented.X-ray diffraction measurements and sorption experiments demonstrated that the intercolumnar spaces in PCT-1 can incorporate various molecules accompanied by lattice expansion.\"]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    #image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "    \n",
    "    #logits_per_image, logits_per_text = model(image, text)\n",
    "    #probs = logits_per_image.softmax(dim=-1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8857447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.find_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0d5f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CIFData(\"./cifs/\")\n",
    "# run only if you have invalid CIF file errors - this will find & delete them\n",
    "# data.find_errors()\n",
    "s, _, _ = data[0]\n",
    "cif_encoder = CrystalGraphConvNet(s[0].shape[-1], s[1].shape[-1],\n",
    "                                n_conv=3,\n",
    "                                n_h=2,\n",
    "                                output_dim=text_features.shape[-1],\n",
    "                                classification=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1bc8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\n",
    "  \"\"\"An octopus (pl: octopuses or octopodes, see below for variants) is a soft-bodied, eight-limbed mollusc of the order Octopoda (/ɒkˈtɒpədə/, ok-TOP-ə-də[3]). The order consists of some 300 species and is grouped within the class Cephalopoda with squids, cuttlefish, and nautiloids. Like other cephalopods, an octopus is bilaterally symmetric with two eyes and a beaked mouth at the center point of the eight limbs.[a] The soft body can radically alter its shape, enabling octopuses to squeeze through small gaps. They trail their eight appendages behind them as they swim. The siphon is used both for respiration and for locomotion, by expelling a jet of water. Octopuses have a complex nervous system and excellent sight, and are among the most intelligent and behaviourally diverse of all invertebrates. Octopuses inhabit various regions of the ocean, including coral reefs, pelagic waters, and the seabed; some live in the intertidal zone and others at abyssal depths. Most species grow quickly, mature early, and are short-lived. In most species, the male uses a specially adapted arm to deliver a bundle of sperm directly into the female's mantle cavity, after which he becomes senescent and dies, while the female deposits fertilised eggs in a den and cares for them until they hatch, after which she also dies. Strategies to defend themselves against predators include the expulsion of ink, the use of camouflage and threat displays, the ability to jet quickly through the water and hide, and even deceit. All octopuses are venomous, but only the blue-ringed octopuses are known to be deadly to humans.\"\"\",\n",
    "  'The title complex was synthesized in 41.6% yield by reactions between Os3(CO)11(CH3CN) and 2,4,6-tri­methyl­hexa­hydro-1,3,5-triazine.Each Os atom exhibits a pseudo-octa­hedral coordination environment, discounting the bridging Os—Os bond.',\n",
    "  'The molecular salt, C23H26N2O2+Cl, was obtained from 1-isobutyl-8,9-dimeth­oxy-3-phenyl-5,6-di­hydro­imidazo[5,1-a]iso­quinoline.In the crystal structure, centrosymmetric dimers are formed by N—HCl and C—HCl hydrogen bonds.',\n",
    "  'The title compound, C16H20N4, was synthesized by cyanation of brom­hexine.The substituted aniline and cyclo­hexane rings are inclined to one another by 37.26 (6)in one mol­ecule and by 22.84 (7)in the other.',\n",
    "  'Your purchase has been completed.Your documents are now available to view.Your purchase has been completed.Your documents are now available to view.',\n",
    "  'Monomeric boroles have been gaining attention as reagents for the synthesis of heterocycles due to their ability to insert atoms into the BC4 ring in a single step.This work demonstrates that insertion chemistry is possible with Diels–Alder dimeric boroles.',\n",
    "  'Deep-blue thermally activated delayed fluorescence (TADF) emitters are promising alternatives for conventional fluorescence and phosphorescence materials.Four new donor–acceptor (D–A)-type TADF molecules incorporating phenazasiline, phenazagermine, and tetramethylcarbazole as weak D units were designed and synthesized.Photophysical investigation revealed that phenazasiline and phenazagermine-based emitters concurrently exhibit blue TADF emissions.',\n",
    "  'Silyl, silylene and silene complexes were accessed via reactions of [(dmpe)2MnH(C2H4)] (1) with hydrosilanes, in some cases followed by ethylene.'\n",
    "]\n",
    "# get longest text in batch\n",
    "context_length = max([len(c) for c in text])\n",
    "context_length = int(np.ceil(context_length / 77) * 77)\n",
    "\n",
    "tokens = clip.tokenize(text, context_length=context_length).reshape(len(text), -1,77).to(device)\n",
    "#print(tokens.shape)\n",
    "\n",
    "embeddings = []\n",
    "# run through clip\n",
    "with torch.no_grad():\n",
    "  for sample in tokens:\n",
    "      ctx = model.encode_text(sample)\n",
    "      # average ctx\n",
    "      ctx = torch.mean(ctx, dim=0)\n",
    "      embeddings.append(ctx)\n",
    "  embeddings = torch.stack(embeddings)\n",
    "  image_features = image_features / image_features.norm(dim=1, keepdim=True)\n",
    "  embeddings = embeddings / embeddings.norm(dim=1, keepdim=True)\n",
    "\n",
    "  # cosine similarity as logits\n",
    "  logit_scale = model.logit_scale.exp()\n",
    "  logits_per_image = logit_scale * image_features @ embeddings.t()\n",
    "  probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "  for i in probs[0]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755d44d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3,4]\n",
    "x.append(5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c6cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test, val, train ratio is 0.1, 0.1, 0.8\n",
    "train_loader, val_loader, test_loader = get_train_val_test_loader(\n",
    "        train_ratio=0.8,\n",
    "        val_ratio=0.1,\n",
    "        test_ratio=0.1,\n",
    "        dataset=data,\n",
    "        collate_fn=collate_pool,\n",
    "        batch_size=1,\n",
    "        return_test=True)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[100, 150], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14636d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(cgcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079cfe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader), len(val_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa9cd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def notify(title, text):\n",
    "    os.system(\"\"\"\n",
    "              osascript -e 'display notification \"{}\" with title \"{}\"'\n",
    "              \"\"\".format(text, title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8c99af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff171c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "cif_encoder = cif_encoder.float()\n",
    "for batch_idx, (inputs, targets, _) in enumerate(train_loader):\n",
    "    inputs = (Variable(inputs[0].to(device, non_blocking=True)),\n",
    "                Variable(inputs[1].to(device, non_blocking=True)),\n",
    "                inputs[2].to(device, non_blocking=True),\n",
    "                [crys_idx.to(device, non_blocking=True) for crys_idx in inputs[3]])\n",
    "    device = \"mps\"\n",
    "    text_embeddings = encode_text([\"cif ashkjdahsd kajshd kasjhd coo\"])\n",
    "    print(targets)\n",
    "    cif_embeddings = cif_encoder(*inputs)\n",
    "    cif_embeddings = cif_embeddings / cif_embeddings.norm(dim=1, keepdim=True)\n",
    "    text_embeddings = text_embeddings / text_embeddings.norm(dim=1, keepdim=True)\n",
    "    print(loss_func(cif_embeddings.float().to(device), text_embeddings.float()))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bc1056",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_text([\"cicosjao\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f9b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "dim = 256\n",
    "embeddings = torch.randn(2, 5)\n",
    "out = embeddings @ embeddings.T\n",
    "print(F.softmax(out, dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f693e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a171ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.normalize(torch.tensor([[1.,2.,3.,4.]])) @ F.normalize(torch.tensor([[1.,2.,3.,4.]])).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bc1c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\"\n",
    "import torch.nn.functional as F\n",
    "def cross_entropy(preds, targets, reduction='none'):\n",
    "    log_softmax = nn.LogSoftmax(dim=-1)\n",
    "    loss = (-targets * log_softmax(preds)).sum(1)\n",
    "    if reduction == \"none\":\n",
    "        return loss\n",
    "    elif reduction == \"mean\":\n",
    "        return loss.mean()\n",
    "def loss_func(feat1, feat2):\n",
    "    # minimize average magnitude of cosine similarity\n",
    "    logits = feat1 @ feat2.T\n",
    "    feat1_similarity = feat1 @ feat1.T\n",
    "    feat2_similarity = feat2 @ feat2.T\n",
    "    targets = F.softmax(\n",
    "            (feat1_similarity + feat2_similarity) / 2, dim=-1\n",
    "        )\n",
    "    print(targets)\n",
    "    feat1_loss = cross_entropy(logits, targets, reduction='none')\n",
    "    feat2_loss = cross_entropy(logits.T, targets.T, reduction='none')\n",
    "    loss =  (feat1_loss + feat2_loss) / 2.0\n",
    "    return loss.mean()\n",
    "loss_func(F.normalize(torch.tensor([ [0., 0.], [1.,1.]])),F.normalize(torch.tensor([[0., 0.], [1., 1.]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2ad8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\"\n",
    "import torch.nn.functional as F\n",
    "notify('Training', 'Training started')\n",
    "def cross_entropy(preds, targets, reduction='none'):\n",
    "    log_softmax = nn.LogSoftmax(dim=-1)\n",
    "    loss = (-targets * log_softmax(preds)).sum(1)\n",
    "    if reduction == \"none\":\n",
    "        return loss\n",
    "    elif reduction == \"mean\":\n",
    "        return loss.mean()\n",
    "def loss_func(feat1, feat2):\n",
    "    # minimize average magnitude of cosine similarity\n",
    "    logits = feat1 @ feat2.T\n",
    "    feat1_similarity = feat1 @ feat1.T\n",
    "    feat2_similarity = feat2 @ feat2.T\n",
    "    targets = F.softmax(\n",
    "            (images_similarity + texts_similarity) / 2, dim=-1\n",
    "        )\n",
    "    feat1_loss = cross_entropy(logits, targets, reduction='none')\n",
    "    feat2_loss = cross_entropy(logits.T, targets.T, reduction='none')\n",
    "    loss =  (feat1_loss + feat2_loss) / 2.0\n",
    "    return loss.mean()\n",
    "def encode_text(targets):\n",
    "    context_length = max([len(c) for c in targets])\n",
    "    context_length = int(np.ceil(context_length / 77) * 77)\n",
    "\n",
    "    tokens = clip.tokenize(targets, context_length=context_length).reshape(len(targets), -1,77).to(device)\n",
    "    embeddings = []\n",
    "    for sample in tokens:\n",
    "        ctx = model.encode_text(sample)\n",
    "        # average ctx\n",
    "        ctx = torch.mean(ctx, dim=0)\n",
    "        embeddings.append(ctx)\n",
    "    text_embeddings = torch.stack(embeddings)\n",
    "    return text_embeddings\n",
    "\n",
    "# model = text encoder (unused image encoder)\n",
    "# cif_encoder\n",
    "model = model.float()\n",
    "cif_encoder = cif_encoder.float()\n",
    "cif_encoder.train()\n",
    "model.train()\n",
    "def train(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        scheduler.step()\n",
    "        for batch_idx, (inputs, targets, _) in enumerate(train_loader):\n",
    "            inputs = (Variable(inputs[0].float()),\n",
    "                         Variable(inputs[1].float()),\n",
    "                         inputs[2],\n",
    "                         [crys_idx for crys_idx in inputs[3]])\n",
    "            cif_embeddings = cif_encoder(*inputs)\n",
    "            text_embeddings = encode_text(targets)\n",
    "            cif_embeddings = cif_embeddings / cif_embeddings.norm(dim=1, keepdim=True)\n",
    "            text_embeddings = text_embeddings / text_embeddings.norm(dim=1, keepdim=True)\n",
    "            #convert text embeddings to list\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_func(cif_embeddings.float().to(device), text_embeddings.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % 1 == 0:\n",
    "                # check validation loss\n",
    "                val_loss = 0\n",
    "                with torch.no_grad():\n",
    "                    for batch_idx, (inputs, targets, _) in enumerate(val_loader):\n",
    "                        inputs = (Variable(inputs[0].float()),\n",
    "                                    Variable(inputs[1].float()),\n",
    "                                    inputs[2],\n",
    "                                    [crys_idx for crys_idx in inputs[3]])\n",
    "                        cif_embeddings = cif_encoder(*inputs)\n",
    "                        text_embeddings = encode_text(targets)\n",
    "                        cif_embeddings = cif_embeddings / cif_embeddings.norm(dim=1, keepdim=True)\n",
    "                        text_embeddings = text_embeddings / text_embeddings.norm(dim=1, keepdim=True)\n",
    "                        val_loss = loss_func(cif_embeddings.float().to(device), text_embeddings.float())\n",
    "\n",
    "                # save checkpoints with loss & epoch metrics\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss.item(),\n",
    "                    'val_loss': val_loss.item()\n",
    "                    }, 'checkpoints/checkpoint_{}.pt'.format(epoch))\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': cif_encoder.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss.item(),\n",
    "                    'val_loss': val_loss.item()\n",
    "                    }, 'checkpoints/checkpoint_cif_{}.pt'.format(epoch))\n",
    "                    \n",
    "                txt = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tVal Loss: {:.6f}'.format(\n",
    "                    epoch, batch_idx*len(targets), len(train_loader),\n",
    "                    100. * batch_idx / len(train_loader), loss.item(), val_loss.item())\n",
    "                print(txt)\n",
    "                notify(f\"Training Epoch {epoch}\", txt)\n",
    "train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a691368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save models to clamp_weights folder\n",
    "torch.save(model.state_dict(), \"clamp_weights/text_encoder.pt\")\n",
    "torch.save(cif_encoder.state_dict(), \"clamp_weights/cif_encoder.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c202efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cif_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4338cea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cif_encoder.load_state_dict(torch.load(\"./checkpoints/checkpoint_cif_val_least.pt\", map_location=torch.device('cpu'))[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f330ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"./checkpoints/checkpoint_clip_val_least.pt\", map_location=torch.device('cpu'))[\"model_state_dict\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "8689fac7afca8cfd8aa85671ea19899a8f2204abddab2f8fabdacf0ec105764e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
